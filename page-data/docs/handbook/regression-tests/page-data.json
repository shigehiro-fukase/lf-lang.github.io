{"componentChunkName":"component---src-templates-documentation-tsx","path":"/docs/handbook/regression-tests","result":{"data":{"markdownRemark":{"id":"96f63950-6ca6-530f-9c7a-ed0605046575","excerpt":"Lingua Franca comes with an extensive set of regression tests that are executed on various platforms automatically whenever an update is pushed to the LF…","html":"<p>Lingua Franca comes with an extensive set of regression tests that are executed on various platforms automatically whenever an update is pushed to the LF repository. There are two categories of tests:</p>\n<ul>\n<li><strong>Unit tests</strong> are Java or Kotlin methods in our code base that are labeled with the <code>@Test</code> directive. These tests check individual functions of the code generation infrastructure. These are located in the <code>src/test</code> directory of each subroject within the repository.</li>\n<li><strong>Integration tests</strong> are complete Lingua Franca programs that are compiled and executed automatically. A test passes if it successfully compiles and runs to completion with normal termination (return code 0). These tests are located in the <code>test</code> directory at the root of the LF repo, with one subdirectory per target language.</li>\n</ul>\n<p>Their implementation can be found in the <code>core/src/integrationTest</code> directory.\nThe integration tests are also executed through JUnit using methods with <code>@Test</code> directives, but they are executed separately.</p>\n<h2 id=\"running-the-tests-from-the-command-line\" style=\"position:relative;\"><a href=\"#running-the-tests-from-the-command-line\" aria-label=\"running the tests from the command line permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Running the Tests From the Command Line</h2>\n<p>To run all unit tests, simply run <code>./gradlew test</code>. Note that also the normal build tasks <code>./gradlew build</code> runs all the unit tests.</p>\n<p>The integration tests can be run using the <code>integrationTest</code> task. However, typically it is not desired to run all tests for all targets locally as it will need the right target tooling and will take a long time.</p>\n<p>To run only the integration tests for one target, we provide the <code>targetTest</code> gradle task. For instance, you can use the following command to run all Rust tests:</p>\n<pre class=\"source-lf language-text\">./gradlew targetTest -Ptarget=Rust</pre>\n<p>You can specify any valid target. If you run the task without specifying the target property <code>./gradlew tagetTest</code> it will produce an error message and list all available targets.</p>\n<p>The <code>targetTest</code> task is essentially a convenient shortcut for the following:</p>\n<pre class=\"source-lf language-text\">./gradew core:integrationTest --test org.lflang.tests.runtime.&lt;target&gt;Test.*</pre>\n<p>If you prefer have more control over which tests are executed, you can also use this more verbose version.</p>\n<p>It is also possible to run a subset of the tests. For example, the C tests are organized into the following categories:</p>\n<ul>\n<li><strong>generic</strong> tests are <code>.lf</code> files located in <code>$LF/test/C/src</code>.</li>\n<li><strong>concurrent</strong> tests are <code>.lf</code> files located in <code>$LF/test/C/src/concurrent</code>.</li>\n<li><strong>federated</strong> tests are <code>.lf</code> files located in <code>$LF/test/C/src/federated</code>.</li>\n<li><strong>multiport</strong> tests are <code>.lf</code> files located in <code>$LF/test/C/src/multiport</code>.</li>\n</ul>\n<p>To invoke only the C tests in the <code>concurrent</code> category, for example, run this:</p>\n<pre class=\"source-lf language-text\">./gradlew core:integrationTest --tests org.lflang.tests.runtime.CTest.runConcurrentTests</pre>\n<p>Sometimes it is convenient to only run a single specific test case. This can be done with the <code>singleTest</code> task. For instance:</p>\n<pre class=\"source-lf language-text\">./gradlew singleTest -DsingleTest=test/C/src/Minimal.lf</pre>\n<h2 id=\"reporting-bugs\" style=\"position:relative;\"><a href=\"#reporting-bugs\" aria-label=\"reporting bugs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reporting Bugs</h2>\n<p>If you encounter a bug or add some enhancement to Lingua Franca, then you should create a regression test either as a system test or a unit test and issue a pull request. System tests are particularly easy to create since they are simply Lingua Franca programs that either compile and execute successfully (the test passes) or fail either to compile or execute.</p>\n<h2 id=\"testing-architecture\" style=\"position:relative;\"><a href=\"#testing-architecture\" aria-label=\"testing architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Testing Architecture</h2>\n<p>System tests can be put in any subdirectory of <code>$LF/test</code> or <code>$LF/example</code>.\nAny <code>.lf</code> file within these directories will be treated as a system test unless they are within a directory named <code>failing</code>, in which case they will be ignored.\nThe tests are automatically indexed by our JUnit-based test infrastructure, which is located in the package <code>core/src/integrationTest</code>. Each target has its own class in the <code>runtime</code> package, with a number of test methods that correspond to particular test categories, such as <code>generic</code>, <code>concurrent</code>, <code>federated</code>, etc. A test can be associated with a particular category by placing it in a directory that matches its name. For instance, we can create a test (e.g., <code>Foo.lf</code>) in <code>test/C/src/concurrent</code>, which will then get indexed under the target <code>C</code> in the category <code>concurrent</code>. Files placed directly in <code>test/C/src</code> will be considered <code>generic</code> <code>C</code> tests, and a file in a directory <code>concurrent/federated</code> will be indexed as <code>federated</code> (corresponding to the nearest containing directory).</p>\n<p><strong>Caution</strong>: adding a <em>new</em> category requires updating an enum in <code>TestRegistry.java</code> and adding a <code>@Test</code>-labeled method to <code>TestBase</code>.</p>\n<h3 id=\"known-failures\" style=\"position:relative;\"><a href=\"#known-failures\" aria-label=\"known failures permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Known Failures</h3>\n<p>Sometimes it is useful to retain tests that have a known failure that should be addressed at a later point. Such tests can simply be put in a directory called <code>failing</code>, which will tell our test indexing code to exclude it.</p>\n<h3 id=\"test-output\" style=\"position:relative;\"><a href=\"#test-output\" aria-label=\"test output permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Test Output</h3>\n<p>Tests are grouped by target and category. It is also reported when, for a given category, there are other targets that feature tests that are missing for the target under test. Tests that either do not have a main reactor or are marked as known failures are reported as “ignored.” For all the tests that were successfully indexed, it is reported how many passed. For each failing test, diagnostics are reported that should help explain the failure. Here is some sample output for <code>Ctest.runConcurrentTests</code>, which runs tests categorized as <code>concurrent</code> for the <code>C</code> target:</p>\n<pre class=\"source-lf language-text\">CTest &gt; runConcurrentTests() STANDARD_OUT\n    ==============================================================================\n    Target: C\n    Description: Run concurrent tests.\n    ==============================================================================\n\n    ==============================================================================\n    Category: CONCURRENT\n    ==============================================================================\n    ------------------------------------------------------------------------------\n    Ignored: 0\n    ------------------------------------------------------------------------------\n\n    ------------------------------------------------------------------------------\n    Covered: 29/33\n    ------------------------------------------------------------------------------\n    Missing: src/concurrent/BankToBank.lf\n    Missing: src/concurrent/BankToBankMultiport.lf\n    Missing: src/concurrent/BankToBankMultiportAfter.lf\n    Missing: src/concurrent/BankToMultiport.lf\n\n    ------------------------------------------------------------------------------\n    Passing: 29/29\n    ------------------------------------------------------------------------------\n</pre>\n<h2 id=\"code-coverage\" style=\"position:relative;\"><a href=\"#code-coverage\" aria-label=\"code coverage permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Code Coverage</h2>\n<p>Code coverage is automatically recorded when running tests.\nA combined report for each subproject can be created by running <code>./gradlew jacocoTestReport</code>.\nFor the <code>core</code> subproject, the html report will be located in <code>build/reports/html/index.html</code>.\nNote that this report will only reflect the coverage of the test that have actually executed.</p>\n<h2 id=\"continuous-integration\" style=\"position:relative;\"><a href=\"#continuous-integration\" aria-label=\"continuous integration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Continuous Integration</h2>\n<p>Each push or pull request will trigger all tests to be run on GitHub Actions. It’s configuration can be found <a href=\"https://github.com/lf-lang/lingua-franca/tree/master/.github/workflows\">here</a>.</p>","headings":[{"value":"Running the Tests From the Command Line","depth":2},{"value":"Reporting Bugs","depth":2},{"value":"Testing Architecture","depth":2},{"value":"Known Failures","depth":3},{"value":"Test Output","depth":3},{"value":"Code Coverage","depth":2},{"value":"Continuous Integration","depth":2}],"frontmatter":{"permalink":"/docs/handbook/regression-tests","title":"Regression Tests","oneline":"Regression Tests for Lingua Franca.","preamble":""}},"prev":{"childMarkdownRemark":{"frontmatter":{"title":"Developer IntelliJ Setup","oneline":"Developer IntelliJ Setup.","permalink":"/docs/handbook/intellij"}}},"next":{"childMarkdownRemark":{"frontmatter":{"title":"Running Benchmarks","oneline":"Running Benchmarks.","permalink":"/docs/handbook/running-benchmarks"}}}},"pageContext":{"id":"5-regression-tests","slug":"/docs/handbook/regression-tests","repoPath":"/packages/documentation/copy/en/developer/Regression Tests.md","previousID":"1d9f0442-2300-5615-9c04-6ee5f2c33793","nextID":"8d78ab4e-cebd-5116-bbe9-871de58f9aeb","lang":"en","modifiedTime":"2023-08-10T11:48:33.006Z"}},"staticQueryHashes":[]}